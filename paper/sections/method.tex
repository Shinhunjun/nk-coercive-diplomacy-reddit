%==============================================================================
% METHOD
%==============================================================================
\section{Method}

\subsection{Data Collection}

We collected Reddit posts from January 2017 to December 2019 using the Arctic Shift API, targeting major subreddits: r/worldnews, r/politics, r/news, r/geopolitics, and r/NeutralPolitics.

\subsubsection{Treatment and Control Groups}

\begin{table}[t]
\centering
\setlength{\tabcolsep}{3pt}
\caption{Dataset Overview}
\begin{tabular}{llrl}
\hline
\textbf{Group} & \textbf{Topic} & \textbf{N} & \textbf{Role} \\
\hline
Treatment & N. Korea & 10,659 & Primary \\
Control 1 & China & 8,024 & Trade confounder \\
Control 2 & Iran & 5,983 & Nuclear comparison \\
Control 3 & Russia & 10,261 & Investigation \\
\hline
\end{tabular}
\label{tab:dataset}
\end{table}

We selected control countries based on their exposure to concurrent geopolitical developments that could confound inference: China for the ongoing U.S.-China trade war, Iran for nuclear diplomacy comparisons (JCPOA negotiations), and Russia for the Mueller investigation that dominated U.S. political discourse during the study period. Using multiple controls allows us to assess robustness across different confounding structures.

\subsubsection{Key Events and Analysis Periods}

To avoid anticipation effects, we define three analysis periods excluding transition months:
\begin{itemize}
    \item \textbf{P1} (2017.01--2018.02): Pre-Announcement
    \item \textbf{P2} (2018.06--2019.01): Singapore-Hanoi
    \item \textbf{P3} (2019.03--2019.12): Post-Hanoi
    \item \textit{Excluded}: 2018.03--05, 2019.02 (Transition periods)
\end{itemize}

Key diplomatic events include the Singapore Summit (2018-06-12), which marked peak diplomatic engagement, and the Hanoi Summit (2019-02-27), which ended without agreement. Figure~\ref{fig:timeline} visually summarizes these periods and events.

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_timeline.png}
\caption{Research Timeline and Key Events. Shaded regions indicate analysis periods: P1 (gray), Transition (yellow), P2 (green), P3 (red).}
\label{fig:timeline}
\end{figure*}

%------------------------------------------------------------------------------
\subsection{Outcome Measurement}

We measure two complementary dimensions of discourse: \textit{sentiment} (emotional valence) and \textit{framing} (how North Korea is narratively positioned).

\subsubsection{Sentiment Analysis}

We compute sentiment using the TweetEval RoBERTa model~\cite{barbieri2020tweeteval}, which maps text to a continuous score from -1 (negative) to +1 (positive). Sentiment captures the \textit{emotional valence} of discourse, measuring whether discussions carry positive or negative affective tone.

\subsubsection{Framing Classification}

We classify each Reddit post into one of five framing categories using GPT-4o-mini with zero-shot prompting:
\begin{itemize}
    \item \textbf{THREAT}: Military threat, nuclear weapons, missiles, war risk
    \item \textbf{ECONOMIC}: Economic sanctions, trade, and financial impacts
    \item \textbf{NEUTRAL}: Descriptive reporting without clear evaluative framing
    \item \textbf{HUMANITARIAN}: Human rights, refugees, civilian welfare
    \item \textbf{DIPLOMACY}: Negotiation, dialogue, summits, peace initiatives
\end{itemize}

The prompt provides category definitions and requires a single label output; the model also returns a confidence score.

For DID analysis, we convert categorical framing to a continuous \textit{diplomacy scale}: THREAT = $-2$, DIPLOMACY = $+2$, and NEUTRAL/ECONOMIC/HUMANITARIAN = $0$. This scale captures the primary distinction between military threat framing and diplomatic engagement framing, allowing direct quantification of how discourse shifts between adversarial and cooperative orientations. We aggregate individual post scores to monthly averages, yielding a continuous outcome variable for each country-month observation.

\subsubsection{Human Annotation Benchmark}

To validate our LLM-based classification in a domain-sensitive setting, we constructed a gold-standard human annotation benchmark. Two military officers with expertise in North Korean affairs independently labeled 1,330 stratified samples (4 countries $\times$ 3 periods $\times$ 5 frames, minimum 10 posts per stratum).

We followed an iterative codebook refinement approach:
\begin{enumerate}
    \item \textbf{Pilot Round}: 100 posts labeled independently with reliability assessment
    \item \textbf{Main Annotation}: Remaining posts labeled in batches with periodic checks
    \item \textbf{Disagreement Resolution}: Structured discussion to produce consensus labels
\end{enumerate}

Inter-rater reliability (Cohen's $\kappa$) and LLM-human agreement metrics are reported in the Results section.

%------------------------------------------------------------------------------
\subsection{Causal Identification}

We estimate the causal impact of summit diplomacy using a Difference-in-Differences (DID) design with North Korea as the treated group and control countries (China, Iran, Russia) as comparisons. This approach follows recent work applying quasi-experimental methods to social media analysis, such as \citet{kumarswamy2025causal}, who used an external platform as a control group to isolate policy effects from confounding offline events. Similarly, we use discourse about other countries as counterfactual comparisons to identify summit-specific effects on North Korea framing.

\subsubsection{Difference-in-Differences Specification}

Our main specification uses two-way fixed effects:

\begin{equation}
Y_{g,t} = \alpha_g + \gamma_t + \beta \big(\text{Treat}_g \times \text{Post}_t\big) + \epsilon_{g,t},
\end{equation}

where $Y_{g,t}$ is the monthly average sentiment (or framing) for group $g$ in month $t$, 
$\alpha_g$ and $\gamma_t$ denote group and month fixed effects, and $\beta$ captures the DID estimate of the summit effect.
We report heteroskedasticity-robust standard errors clustered at the group level.

\subsubsection{Parallel Trends Validation}

We assess the parallel trends assumption by testing for differential pre-treatment trends between North Korea and each control group:

\begin{equation}
Y_{g,t} = \alpha + \delta_1 t + \delta_2 \text{Treat}_g + \delta_3 (t \times \text{Treat}_g) + \epsilon_{g,t},
\end{equation}

where $t$ is a linear month index in the pre-period. A statistically significant $\delta_3$ indicates a pre-trend violation. Results are reported in the Results section.

%------------------------------------------------------------------------------
\subsection{Network Structure Analysis}

Beyond content-level changes, we examine whether diplomatic events reorganize the \textit{structure} of discourse using GraphRAG~\cite{edge2024graphrag}, Microsoft's graph-based retrieval-augmented generation framework. We construct knowledge graphs from Reddit discussions for each analysis period.

\subsubsection{GraphRAG Customization}

We adapted GraphRAG for international relations discourse through three customizations:

\textbf{Domain-Specific Entity Types.} We extended the default entity taxonomy to include WEAPON (e.g., ``ICBM,'' ``nuclear warhead'') and POLICY (e.g., ``denuclearization,'' ``maximum pressure'') categories, enabling extraction of security-relevant concepts central to North Korea discourse.

\textbf{Relationship Extraction Prompts.} We modified extraction prompts to include NK-specific examples (Singapore Summit, missile tests) and guidelines for classifying relationship strength along a threat-diplomacy spectrum.

\textbf{Community Report Enhancement.} We added fields for narrative connectivity analysis, including hub entity identification, bridge narrative detection, and cohesion level assessment.

\subsubsection{Network Metrics}

We compute the following structural metrics for each period:
\begin{itemize}
    \item \textbf{Network density}: Proportion of realized connections among entities
    \item \textbf{Entity count}: Number of unique discourse actors
    \item \textbf{Community count}: Number of detected narrative clusters
    \item \textbf{Relationship framing}: Classification of edges as threat/peace/neutral
    \item \textbf{Keyword evolution}: Dominant themes in community summaries
\end{itemize}

This structural analysis tests whether content-level framing shifts are accompanied by reorganization of discourse networks.
