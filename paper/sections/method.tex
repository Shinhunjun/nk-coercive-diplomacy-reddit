\section{Method}
\subsection{Data Collection}
\textbf{Agenda-Setting Posts (Primary Data):} We collected Reddit posts from January 2017 to June 2019 using the Arctic Shift API~\cite{arcticshift2024}, targeting eight major subreddits: r/worldnews, r/politics, r/news, r/geopolitics, r/korea, r/northkorea, r/AskAnAmerican, and r/NeutralPolitics. To ensure comprehensive coverage, we employed a keyword-based retrieval strategy, querying for posts containing country-specific keywords (e.g., ``North Korea'', ``China'', ``Iran'', ``Russia'') to construct our treatment and control groups. All posts were filtered to English. As detailed in Table~\ref{tab:dataset}, our final primary dataset consists of 29,688 posts, comprising 10,448 North Korea-related posts (treatment) and 19,240 posts across three control groups.

\textbf{Audience Response Data:} While our primary causal analysis focuses on posts ($N=29,688$), we also collected the full comment trees (root comments and all nested replies) for the top-5 most upvoted root comments from each post. This approach captures both highly visible audience responses ($N=255,391$ total comments across $\sim$52,000 root comments) and the cascading discussions they trigger, representing the most influential layer of participatory discourse.

\textbf{Analytical Role of Comments:} We treat audience comments differently across analytical stages. In content-level analyses, comments are used to assess whether post-level effects are reflected in highly visible, socially reinforced audience interpretations. Accordingly, comment-level analyses do not constitute independent causal estimates. In contrast, in network analyses, comments are examined separately to capture interactional and participatory discourse structures that are distinct from agenda-setting posts.

\textbf{Treatment and Control Groups:} To isolate the causal impact of summit diplomacy, it is essential to control for concurrent geopolitical developments that could confound inference. Relying solely on longitudinal observations of the treatment group (North Korea) risks misinterpreting broader fluctuations in Reddit users' foreign policy sentiment as specific effects of the summits.

\begin{table}[t]
\centering
\setlength{\tabcolsep}{3pt}
\caption{Dataset Overview}
\begin{tabular}{llrr}
\hline
\textbf{Group} & \textbf{Topic} & \textbf{Posts} & \textbf{Comments} \\
\hline
Treatment & N. Korea & 10,448 & 70,879 \\
Control 1 & China & 5,921 & 62,057 \\
Control 2 & Iran & 4,749 & 40,572 \\
Control 3 & Russia & 8,570 & 81,883 \\
\hline
\textbf{Total} & & \textbf{29,688} & \textbf{255,391} \\
\hline
\end{tabular}
\label{tab:dataset}
\end{table}
We selected control countries exposed to contemporaneous high-salience geopolitical events but not subject to U.S.--North Korea summit diplomacy: China (trade conflict), Iran (post-JCPOA tensions), and Russia (U.S. election interference).
Using multiple controls allows us to assess robustness across different confounding structures. However, the validity of a DiD design rests on the parallel trends assumption: treated and control groups must exhibit similar trends in the outcome variable prior to the intervention. We verified this assumption for all groups (see Appendix Tables~\ref{tab:app_pt_sentiment} and~\ref{tab:app_pt_framing}). For sentiment, all three control groups satisfied parallel trends ($p > 0.05$ for all comparisons). For framing, China and Iran satisfied parallel trends, while Russia exhibited a significant violation for P1$\rightarrow$P2 ($p = 0.01$), likely reflecting differential political attention to Russia during the pre-treatment period. When parallel trends assumptions are violated, including such controls can bias DiD estimates rather than strengthen identification. Accordingly, we adopt a conservative strategy and exclude Russia from framing analyses where violations are detected. Consequently, we exclude Russia from framing analyses for the Singapore Summit effect and retain China and Iran as primary counterfactuals.

\textbf{Key Events and Analysis Periods:} To avoid anticipation effects, we define three analysis periods excluding transition months and Figure~\ref{fig:timeline} visually summarizes these periods and events:
\begin{itemize}
    \item \textbf{P1} (2017.01--2018.02): Pre-Announcement
    \item \textbf{P2} (2018.06--2019.01): Singapore-Hanoi
    \item \textbf{P3} (2019.03--2019.12): Post-Hanoi
    \item \textit{Excluded}: 2018.03--05, 2019.02 (Transition periods)
\end{itemize}

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_timeline_v2.pdf}
\caption{Research Timeline and Key Events. Dashed brackets indicate analysis periods: P1 (Pre-Announcement), P2 (Singapore-Hanoi), P3 (Post-Hanoi). Transition periods are excluded from analysis to avoid anticipation effects.}
\label{fig:timeline}
\end{figure*}

\subsection{Outcome Measurement}
To answer our research questions, we measure two complementary dimensions of discourse: \textit{sentiment} (emotional valence) and \textit{framing} (how North Korea is narratively positioned). 

\textbf{Sentiment Analysis: } We use the TweetEval RoBERTa model~\cite{barbieri2020tweeteval}, a widely adopted benchmark for social media sentiment analysis, producing continuous scores from -1 (negative) to +1 (positive). 

\textbf{Framing Classification: } We classify each Reddit post into one of five framing categories (THREAT, ECONOMIC, NEUTRAL, HUMANITARIAN, DIPLOMACY) using GPT-4o-mini (API version: July 2024, temperature = 0, seed = 42 for reproducibility) within a ``Codebook LLM'' framework, which treats the model as a clear-cut measurement instrument rather than a black box. The prompt provides category definitions and requires a single label output; the model also returns a confidence score.
Detailed prompt instructions and category definitions are provided in Appendix~\ref{app:llm_prompt}. To ensure classification quality, we retained only predictions with confidence $\geq 0.90$, yielding 27,863 posts (94\% of the original sample). For DiD analysis, we convert categorical framing to a continuous \textit{diplomacy scale}: THREAT = $-2$, DIPLOMACY = $+2$, and NEUTRAL/ECONOMIC/HUMANITARIAN = $0$. This scale captures the primary distinction between military threat framing and diplomatic engagement framing, allowing direct quantification of how discourse shifts between adversarial and cooperative orientations. While economic sanctions can function as coercive instruments in international relations, we treat ECONOMIC framing as neutral in our primary specification because our theoretical focus is on the rhetorical distinction between \textit{military threats} and \textit{diplomatic dialogue}---the two poles most directly affected by summit diplomacy. A robustness check treating ECONOMIC as partially coercive (ECONOMIC = $-1$) yields similar or stronger results, suggesting our main specification is conservative (see Appendix~\ref{app:robustness}). We aggregate individual post scores to monthly averages, yielding a continuous outcome variable for each country-month observation. This operationalization follows prior work emphasizing the distinction between affective tone and substantive narrative positioning.

\textbf{Human Annotation Benchmark: } To validate our LLM-based classification in a domain-sensitive setting, we constructed a gold-standard human annotation benchmark. Two military officers with expertise in North Korean affairs independently labeled 500 stratified samples (4 countries $\times$ 3 periods $\times$ 5 frames). We provide detailed information in the Results section.

\subsection{Causal Identification}
We estimate the causal impact of summit diplomacy using a Difference-in-Differences (DiD) design,
a widely used quasi-experimental approach for evaluating the effects of discrete political events
in observational data~\cite{berger2020tarp,yang2022effects}. Following Kumarswamy et al.~\cite{kumarswamy2025}, who used a control platform to isolate policy effects, we leverage multiple control countries to separate summit impacts from global geopolitical confounds.
By using China, Iran, and Russia as counterfactuals, we control for external shocks such as the U.S.-China trade war, JCPOA withdrawal tensions, and the Mueller investigation, respectively. This design ensures that observed changes in North Korea discourse are attributable to summit diplomacy rather than general fluctuations in foreign policy attention or sentiment.

\textbf{Difference-in-Differences Specification:} Our main specification uses two-way fixed effects:
\begin{equation}
Y_{g,t} = \alpha_g + \gamma_t + \beta \big(\text{Treat}_g \times \text{Post}_t\big) + \epsilon_{g,t},
\end{equation}
where $Y_{g,t}$ is the monthly average sentiment (or framing) for group $g$ in month $t$, 
$\alpha_g$ and $\gamma_t$ denote group and month fixed effects, and $\beta$ captures the DID estimate of the summit effect. We report heteroskedasticity-robust standard errors clustered at the group level. We explicitly verified the parallel trends assumption, as detailed in the Data Collection subsection above.

\textbf{Causal Scope:}
Our primary causal identification is defined at the post level, where the unit of
analysis is the agenda-setting initial post.
We additionally estimate Difference-in-Differences models at the comment level
to assess whether post-level effects extend to highly visible audience responses.
These comment-level estimates are interpreted as supporting evidence of propagation
and external validity, rather than as independent causal identification.

\subsection{Network Structure Analysis}
Beyond content-level changes, we examine whether diplomatic events reorganize the \textit{structure} of discourse. We adopt a \textbf{GraphRAG-inspired indexing pipeline}~\cite{edge2024graphrag}, leveraging its entity and relationship extraction capabilities to construct structured knowledge graphs. Recent advances have demonstrated that Large Language Models (LLMs) can effectively extract structured knowledge from unstructured text across complex domains, often outperforming traditional information extraction methods~\cite{Anuyah2025CoDeKG,Yang2025SepsisKG}. This approach has proven particularly valuable for analyzing political discourse, where LLMs can identify key actors, events, and their relationships from noisy media content~\cite{Arslan2024PoliticalRAG,Fadda2025LLM_KG_Viewpoints}. While GraphRAG is primarily designed for retrieval-augmented generation, we utilize only its initial \textbf{indexing phase} (which extracts entities and relationships via LLM to build a structured knowledge graph) as a scalable, automated method for constructing the inputs needed for Discourse Network Analysis (DNA)~\cite{leifeld2016policy}. This methodology aligns with recent frameworks that use LLM-constructed graphs to capture complex multi-level relationships and unification of fragmented evidence~\cite{Feng2025BioRAG,Ling2026LLM_KG_Review}.
Unlike simple keyword co-occurrence networks, which cannot distinguish whether two entities co-occur in a ``threat'' or ``negotiation'' context, this approach extracts semantically meaningful relationships, enabling analysis of \textit{narrative connectivity} rather than mere lexical proximity. We utilize this pipeline to generate knowledge graphs from Reddit discussions for each analysis period.

\textbf{Graph Construction and Customization: }We customized the graph extraction prompts to capture domain-specific constraints. We extended the default entity taxonomy to include \textbf{WEAPON} (e.g., ``ICBM,'' ``nuclear warhead'') and \textbf{POLICY} (e.g., ``denuclearization,'' ``maximum pressure'') categories, ensuring the retrieval of security-relevant concepts central to North Korea discourse.

\textbf{Hierarchical Framing Classification: }To ensure methodological consistency between content and structural analyses, we applied the same ``Codebook LLM'' classifier (GPT-4o-mini) used for individual posts to the structural outputs of the graph-based indexing pipeline:
\begin{enumerate}
    \item \textbf{Edge Classification}: We classified the extracted relationship descriptions between entities to determine if the structural link represented a ``Threat,'' ``Diplomacy,'' or other connection type.
    \item \textbf{Community Classification}: We classified the generated summaries of each community to identify the dominant narrative orientation of that cluster.
\end{enumerate}

\textbf{Network Metrics: } We compute three key structural metrics to test for discourse reorganization:
\begin{enumerate}
    \item \textbf{Network Density}: Measures structural consolidation and discourse cohesion (testing for fragmentation vs. unification).
    \item \textbf{Edge Framing Distribution}: Quantifies the proportion of adversarial vs. diplomatic relationships, providing a structural test of asymmetric persistence in framing.
    \item \textbf{Community Composition}: Identifies thematic diversification by tracking the emergence of non-security clusters (e.g., humanitarian, economic) in the community structure.
\end{enumerate}
This structural analysis tests whether content-level framing shifts are accompanied by reorganization of discourse networks.
