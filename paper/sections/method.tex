%==============================================================================
% METHOD
%==============================================================================
\section{Method}

\subsection{Data Collection}

We collected Reddit posts from January 2017 to December 2019 using the Arctic Shift API (based on the Pushshift dataset~\cite{baumgartner2020}), targeting major subreddits: r/worldnews, r/politics, r/news, r/geopolitics, and r/NeutralPolitics. All posts were filtered to English using Reddit's language metadata.

\subsubsection{Treatment and Control Groups}

\begin{table}[t]
\centering
\setlength{\tabcolsep}{3pt}
\caption{Dataset Overview}
\begin{tabular}{llrl}
\hline
\textbf{Group} & \textbf{Topic} & \textbf{N} & \textbf{Role} \\
\hline
Treatment & N. Korea & 10,659 & Primary \\
Control 1 & China & 8,024 & Trade confounder \\
Control 2 & Iran & 5,983 & Nuclear comparison \\
Control 3 & Russia & 10,261 & Investigation \\
\hline
\end{tabular}
\label{tab:dataset}
\end{table}

We selected control countries based on their exposure to concurrent geopolitical developments that could confound inference: China for the ongoing U.S.-China trade war, Iran for nuclear diplomacy comparisons (JCPOA negotiations), and Russia for the Mueller investigation that dominated U.S. political discourse during the study period. Using multiple controls allows us to assess robustness across different confounding structures. As shown in the parallel trends validation (Section~\ref{sec:parallel_trends}), Russia exhibited significant pre-treatment trend violations for framing, likely due to its entanglement with domestic U.S. politics, and was therefore excluded from framing analyses while China and Iran remained valid controls.

\subsubsection{Key Events and Analysis Periods}

To avoid anticipation effects, we define three analysis periods excluding transition months:
\begin{itemize}
    \item \textbf{P1} (2017.01--2018.02): Pre-Announcement
    \item \textbf{P2} (2018.06--2019.01): Singapore-Hanoi
    \item \textbf{P3} (2019.03--2019.12): Post-Hanoi
    \item \textit{Excluded}: 2018.03--05, 2019.02 (Transition periods)
\end{itemize}

Key diplomatic events include the Singapore Summit (2018-06-12), which marked peak diplomatic engagement, and the Hanoi Summit (2019-02-27), which ended without agreement. Figure~\ref{fig:timeline} visually summarizes these periods and events.

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_timeline.png}
\caption{Research Timeline and Key Events. Shaded regions indicate analysis periods: P1 (gray), Transition (yellow), P2 (green), P3 (red).}
\label{fig:timeline}
\end{figure*}

%------------------------------------------------------------------------------
\subsection{Outcome Measurement}

We measure two complementary dimensions of discourse: \textit{sentiment} (emotional valence) and \textit{framing} (how North Korea is narratively positioned).

\subsubsection{Sentiment Analysis}

We compute sentiment using the TweetEval RoBERTa model~\cite{barbieri2020tweeteval}, which maps text to a continuous score from -1 (negative) to +1 (positive). Sentiment captures the \textit{emotional valence} of discourse, measuring whether discussions carry positive or negative affective tone.

\subsubsection{Framing Classification}

We classify each Reddit post into one of five framing categories using GPT-4o-mini within a ``Codebook LLM'' framework~\cite{halterman2025codebook,zhang2025codebook}, which treats the model as a clear-cut measurement instrument rather than a black box. Using zero-shot prompting with explicit definitions:
\begin{itemize}
    \item \textbf{THREAT}: Military threat, nuclear weapons, missiles, war risk
    \item \textbf{ECONOMIC}: Economic sanctions, trade, and financial impacts
    \item \textbf{NEUTRAL}: Descriptive reporting without clear evaluative framing
    \item \textbf{HUMANITARIAN}: Human rights, refugees, civilian welfare
    \item \textbf{DIPLOMACY}: Negotiation, dialogue, summits, peace initiatives
\end{itemize}

The prompt provides category definitions and requires a single label output; the model also returns a confidence score.

For DID analysis, we convert categorical framing to a continuous \textit{diplomacy scale}: THREAT = $-2$, DIPLOMACY = $+2$, and NEUTRAL/ECONOMIC/HUMANITARIAN = $0$. This scale captures the primary distinction between military threat framing and diplomatic engagement framing, allowing direct quantification of how discourse shifts between adversarial and cooperative orientations. We aggregate individual post scores to monthly averages, yielding a continuous outcome variable for each country-month observation.

\subsubsection{Human Annotation Benchmark}

To validate our LLM-based classification in a domain-sensitive setting, we constructed a gold-standard human annotation benchmark. Two military officers with expertise in North Korean affairs independently labeled 1,330 stratified samples (4 countries $\times$ 3 periods $\times$ 5 frames, minimum 10 posts per stratum).

We followed an iterative codebook refinement approach:
\begin{enumerate}
    \item \textbf{Pilot Round}: 100 posts labeled independently with reliability assessment
    \item \textbf{Main Annotation}: Remaining posts labeled in batches with periodic checks
    \item \textbf{Disagreement Resolution}: Structured discussion to produce consensus labels
\end{enumerate}

Inter-rater reliability (Cohen's $\kappa$) and LLM-human agreement metrics are reported in the Results section.

%------------------------------------------------------------------------------
\subsection{Causal Identification}

We estimate the causal impact of summit diplomacy using a Difference-in-Differences (DID) design with North Korea as the treated group and control countries (China, Iran, Russia) as comparisons. This approach follows recent work applying quasi-experimental methods to social media analysis. Specifically, just as Kumarswamy et al.~\cite{kumarswamy2025} utilized a control platform (Twitter) to isolate Parler's policy effects from concurrent offline events (e.g., the Capitol riot), we leverage multiple control countries to separate the effects of U.S.-North Korea summits from confounding global geopolitical developments.

By using China, Iran, and Russia as counterfactuals, we control for external shocks such as the U.S.-China trade war, JCPOA withdrawal tensions, and the Mueller investigation, respectively. This design ensures that observed changes in North Korea discourse are attributable to summit diplomacy rather than general fluctuations in foreign policy attention or sentiment.

\subsubsection{Difference-in-Differences Specification}

Our main specification uses two-way fixed effects:

\begin{equation}
Y_{g,t} = \alpha_g + \gamma_t + \beta \big(\text{Treat}_g \times \text{Post}_t\big) + \epsilon_{g,t},
\end{equation}

where $Y_{g,t}$ is the monthly average sentiment (or framing) for group $g$ in month $t$, 
$\alpha_g$ and $\gamma_t$ denote group and month fixed effects, and $\beta$ captures the DID estimate of the summit effect.
We report heteroskedasticity-robust standard errors clustered at the group level.

\subsubsection{Parallel Trends Validation}

We assess the parallel trends assumption---a critical requirement for valid DiD inference~\cite{egami2023using}---by testing for differential pre-treatment trends between North Korea and each control group:

\begin{equation}
Y_{g,t} = \alpha + \delta_1 t + \delta_2 \text{Treat}_g + \delta_3 (t \times \text{Treat}_g) + \epsilon_{g,t},
\end{equation}

where $t$ is a linear month index in the pre-period. A statistically significant $\delta_3$ indicates a pre-trend violation. Results are reported in the Results section.

%------------------------------------------------------------------------------
\subsection{Network Structure Analysis}

Beyond content-level changes, we examine whether diplomatic events reorganize the \textit{structure} of discourse. To do this, we leverage the \textbf{graph construction pipeline} of Microsoft's GraphRAG framework~\cite{edge2024graphrag}. While GraphRAG is primarily designed for retrieval-augmented generation, its initial \textbf{indexing phase}---which extracts entities and relationships via LLM to build a structured knowledge graph---provides a scalable, automated method for constructing the inputs needed for Discourse Network Analysis (DNA)~\cite{leifeld2016policy}. Unlike simple keyword co-occurrence networks, which cannot distinguish whether two entities co-occur in a ``threat'' or ``negotiation'' context, GraphRAG extracts semantically meaningful relationships, enabling analysis of \textit{narrative connectivity} rather than mere lexical proximity. We utilize this pipeline to generate knowledge graphs from Reddit discussions for each analysis period.

\subsubsection{Graph Construction and Customization}

We customized the graph extraction prompts to capture domain-specific constraints. We extended the default entity taxonomy to include \textbf{WEAPON} (e.g., ``ICBM,'' ``nuclear warhead'') and \textbf{POLICY} (e.g., ``denuclearization,'' ``maximum pressure'') categories, ensuring the retrieval of security-relevant concepts central to North Korea discourse.

\subsubsection{Hierarchical Frame Classification}

To ensure methodological consistency between content and structural analyses, we applied the same ``Codebook LLM'' classifier (GPT-4o-mini) used for individual posts to the structural outputs of the GraphRAG pipeline:
\begin{enumerate}
    \item \textbf{Edge Classification}: We classified the extracted relationship descriptions between entities to determine if the structural link represented a ``Threat,'' ``Diplomacy,'' or other connection type.
    \item \textbf{Community Classification}: We classified the generated summaries of each community to identify the dominant narrative orientation of that cluster.
\end{enumerate}

\subsubsection{Network Metrics}

We compute three key structural metrics to test for discourse reorganization:
\begin{enumerate}
    \item \textbf{Network Density}: Measures structural consolidation and discourse cohesion (testing for fragmentation vs. unification).
    \item \textbf{Edge Framing Distribution}: Quantifies the proportion of adversarial vs. diplomatic relationships, providing a structural test of the ``ratchet effect.''
    \item \textbf{Community Composition}: Identifies thematic diversification by tracking the emergence of non-security clusters (e.g., humanitarian, economic) in the community structure.
\end{enumerate}

This structural analysis tests whether content-level framing shifts are accompanied by reorganization of discourse networks.
