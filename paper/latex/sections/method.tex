%==============================================================================
% METHOD
%==============================================================================
\section{Method}

\subsection{Data Collection}

We collected Reddit posts from January 2017 to December 2019 using the Arctic Shift API, targeting major subreddits: r/worldnews, r/politics, r/news, r/geopolitics, and r/NeutralPolitics.

\subsubsection{Treatment and Control Groups}

\begin{table}[t]
\centering
\setlength{\tabcolsep}{3pt}
\caption{Dataset Overview}
\begin{tabular}{llrl}
\hline
\textbf{Group} & \textbf{Topic} & \textbf{N} & \textbf{Role} \\
\hline
Treatment & N. Korea & 10,659 & Primary \\
Control 1 & China & 8,024 & Trade confounder \\
Control 2 & Iran & 5,983 & Nuclear comparison \\
Control 3 & Russia & 10,261 & Investigation \\
\hline
\end{tabular}
\label{tab:dataset}
\end{table}

\subsubsection{Key Events and Analysis Periods}

To avoid anticipation effects, we define three analysis periods excluding transition months:
\begin{itemize}
    \item \textbf{P1} (2017.01--2018.02): Pre-Announcement
    \item \textbf{P2} (2018.06--2019.01): Singapore-Hanoi
    \item \textbf{P3} (2019.03--2019.12): Post-Hanoi
    \item \textit{Excluded}: 2018.03--05, 2019.02 (Transition periods)
\end{itemize}

Key diplomatic events include the Singapore Summit (2018-06-12), which marked peak diplomatic engagement, and the Hanoi Summit (2019-02-27), which ended without agreement.

%------------------------------------------------------------------------------
\subsection{Outcome Measurement}

We measure two complementary dimensions of discourse: \textit{framing} (how North Korea is narratively positioned) and \textit{sentiment} (emotional valence).

\subsubsection{Framing Classification}

We classify each Reddit post into one of five framing categories using GPT-4o-mini with zero-shot prompting:
\begin{itemize}
    \item \textbf{THREAT} (-2): Military threat, nuclear weapons, missiles, war risk
    \item \textbf{ECONOMIC} (-1): Economic sanctions, trade, and financial impacts
    \item \textbf{NEUTRAL} (0): Descriptive reporting without clear evaluative framing
    \item \textbf{HUMANITARIAN} (+1): Human rights, refugees, civilian welfare
    \item \textbf{DIPLOMACY} (+2): Negotiation, dialogue, summits, peace initiatives
\end{itemize}

The prompt provides category definitions and requires a single label output; the model also returns a confidence score.

\subsubsection{Sentiment Analysis}

We compute sentiment using a RoBERTa-based sentiment model\footnote{cardiffnlp/twitter-roberta-base-sentiment-latest}. Sentiment is mapped to a continuous score from -1 (negative) to +1 (positive). While framing captures \textit{how} North Korea is discussed, sentiment captures \textit{emotional valence}, enabling complementary measurement of content change.

\subsubsection{Human Annotation Benchmark}

To validate our LLM-based classification in a domain-sensitive setting, we constructed a gold-standard human annotation benchmark. Two military officers with expertise in North Korean affairs independently labeled 1,330 stratified samples (4 countries $\times$ 3 periods $\times$ 5 frames, minimum 10 posts per stratum).

We followed an iterative codebook refinement approach:
\begin{enumerate}
    \item \textbf{Pilot Round}: 100 posts labeled independently with reliability assessment
    \item \textbf{Main Annotation}: Remaining posts labeled in batches with periodic checks
    \item \textbf{Disagreement Resolution}: Structured discussion to produce consensus labels
\end{enumerate}

Inter-rater reliability (Cohen's $\kappa$) and LLM-human agreement metrics are reported in Section~5 (RQ3).

%------------------------------------------------------------------------------
\subsection{Causal Identification}

We estimate the causal impact of summit diplomacy using a Difference-in-Differences (DID) design with North Korea as the treated group and control countries (China, Iran, Russia) as comparisons.

\subsubsection{Difference-in-Differences Specification}

Our main specification uses two-way fixed effects:

\begin{equation}
Y_{g,t} = \alpha_g + \gamma_t + \beta \big(\text{Treat}_g \times \text{Post}_t\big) + \epsilon_{g,t},
\end{equation}

where $Y_{g,t}$ is the monthly average sentiment (or framing) for group $g$ in month $t$, 
$\alpha_g$ and $\gamma_t$ denote group and month fixed effects, and $\beta$ captures the DID estimate of the summit effect.
We report heteroskedasticity-robust standard errors clustered at the group level.

\subsubsection{Parallel Trends Validation}

We assess the parallel trends assumption by testing for differential pre-treatment trends between North Korea and each control group:

\begin{equation}
Y_{g,t} = \alpha + \delta_1 t + \delta_2 \text{Treat}_g + \delta_3 (t \times \text{Treat}_g) + \epsilon_{g,t},
\end{equation}

where $t$ is a linear month index in the pre-period. A statistically significant $\delta_3$ indicates a pre-trend violation. Results are reported in Section~5.

%------------------------------------------------------------------------------
\subsection{Additional Analyses: Network Structure}

Beyond content-level changes, we examine whether diplomatic events reorganize the \textit{structure} of discourse using GraphRAG~\cite{edge2024graphrag}. We construct knowledge graphs from Reddit discussions for each period, extracting entities (persons, countries, events, policies, weapons) and their relationships.

Network-level metrics include:
\begin{itemize}
    \item \textbf{Density}: Proportion of possible connections realized
    \item \textbf{Community structure}: Hierarchical clustering of narratives
    \item \textbf{Relationship framing}: Classification of edges as threat/peace/neutral
    \item \textbf{Keyword evolution}: Dominant themes in community summaries
\end{itemize}

This structural analysis addresses RQ2 by testing whether content-level framing shifts are accompanied by reorganization of discourse networks.
