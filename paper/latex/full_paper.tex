% Main LaTeX file - ICWSM 2025 Paper
% Based on official AAAI/ICWSM template
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai25}  % DO NOT CHANGE THIS (use submission for anonymous)
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS

% Additional allowed packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{stfloats} % Allow figure* at bottom

% Checklist macros
\newcommand{\answerYes}[1]{\textcolor{blue}{#1}} 
\newcommand{\answerNo}[1]{\textcolor{teal}{#1}} 
\newcommand{\answerNA}[1]{\textcolor{gray}{#1}} 
\newcommand{\answerTODO}[1]{\textcolor{red}{#1}} 
\usepackage{xcolor} 

% PDF Info
\pdfinfo{
/Title (Summit Diplomacy and Social Media Framing)
/Author (Anonymous Submission)
/TemplateVersion (2025.1)
}

\setcounter{secnumdepth}{0} % No section numbers

% Title - Must be in Title Case
\title{Summit Diplomacy and Social Media Framing: \\
A Causal Analysis of U.S.-North Korea Summits on Reddit Public Opinion}

% For anonymous submission
\author{
    Anonymous Submission
}
\affiliations{
    
}

% For camera-ready (uncomment and fill in):
% \author{
%     Jun Sin\textsuperscript{\rm 1}
% }
% \affiliations{
%     \textsuperscript{\rm 1}University of Texas at Austin\\
%     Austin, TX, USA\\
%     jun.sin@utexas.edu
% }

\begin{document}

\maketitle

\begin{abstract}
% === BEGIN: sections/abstract.tex ===
% Abstract

High-stakes diplomatic summits can substantially reshape how foreign adversaries are discussed in public discourse, yet the causal mechanisms underlying these shifts remain poorly understood in online environments. This study examines how the 2018 Singapore Summit and the failed 2019 Hanoi Summit affected the framing of North Korea on Reddit. Leveraging over 35,000 Reddit posts from 2017--2019, we combine a Difference-in-Differences design with large language model (LLM)-based framing classification validated against expert human annotations by military officers.

Our results show that the Singapore Summit produced a significant shift away from threat-oriented discourse toward diplomacy-oriented framing, accompanied by more modest improvements in sentiment. In contrast, the Hanoi Summit failure triggered a partial reversal in both framing and sentiment, though the earlier framing gains were not fully undone. Beyond content-level change, we find evidence that diplomatic events reorganize the structure of online discourse by altering the connectivity and prominence of dominant narratives.

Together, these findings suggest that successful diplomatic engagement can induce asymmetric and durable changes in how adversaries are framed in online discourse. Methodologically, this study demonstrates how validated LLM-based framing analysis combined with causal inference can advance the study of event-driven opinion dynamics in computational social science.


% === END: sections/abstract.tex ===
\end{abstract}

% Optional: Links to code/data (uncomment for camera-ready)
% \begin{links}
%     \link{Code}{https://github.com/...}
%     \link{Datasets}{https://...}
% \end{links}

% Main sections
% === BEGIN: sections/introduction.tex ===
\section{Introduction}

Public opinion toward foreign adversaries is rarely shaped by isolated facts alone, but rather by how international events are framed and discussed in public discourse. In the context of diplomacy, high-stakes summits serve not only as policy interventions but also as salient narrative events that can reorient how adversary states are collectively interpreted, evaluated, and debated.

Existing research on public opinion and foreign policy has largely relied on survey-based measures of approval or sentiment, often focusing on short-term emotional responses to international crises. While such approaches capture shifts in affect, they provide limited insight into how the \textit{structure and framing} of discourse evolve over time—particularly in online environments where narratives are co-produced by media, political elites, and the public. In particular, survey instruments are ill-suited to capture how narratives are contested, reproduced, and restructured within participatory online discourse.

This study argues that understanding diplomatic effects on public opinion requires moving beyond sentiment alone to examine framing dynamics: how adversaries are discussed, which narratives become dominant, and how these narratives persist or dissipate following political events. We focus on two closely linked but distinct dimensions of online discourse: (1) \textit{content}, reflected in sentiment and framing, and (2) \textit{structure}, reflected in how narratives are interconnected within discourse networks. Focusing solely on content-level change risks overlooking how diplomatic events may reorganize the relationships among narratives themselves.

We examine these dynamics through the case of U.S.–North Korea summit diplomacy. The historic 2018 Singapore Summit between U.S. President Donald Trump and North Korean leader Kim Jong Un marked the first-ever meeting between sitting leaders of the two nations and was widely framed as a diplomatic breakthrough. Less than a year later, the February 2019 Hanoi Summit collapsed without agreement, providing a contrasting case of diplomatic failure. Together, these events constitute a natural experiment for examining how successful and failed diplomacy causally reshape online discourse toward a long-standing adversary.

Leveraging large-scale Reddit discussions from 2017 to 2019, we combine a Difference-in-Differences research design with validated LLM-based framing classification to identify causal shifts in discourse. In addition to measuring changes in sentiment and framing, we examine whether diplomatic events also reorganize the underlying structure of discourse by altering narrative connectivity and centrality within discourse networks.

By integrating content-level and structural analyses, this study contributes to computational social science in three ways. First, it provides causal evidence that diplomatic summits significantly reshape how adversary nations are framed in online discourse. Second, it demonstrates that these effects are asymmetric: successful diplomacy produces larger framing shifts that tend to persist more strongly than subsequent diplomatic failures fully reverse. Third, it introduces a scalable yet domain-sensitive methodology that combines LLM-based analysis with expert human validation to study geopolitical discourse at scale.

\subsection{Research Questions}

This study investigates how high-stakes diplomatic events reshape online discourse toward a foreign adversary across both content and structure. Specifically, we ask:

\begin{itemize}
    \item \textbf{RQ1 (Content Change)}: How do high-stakes diplomatic summits causally affect sentiment and framing toward North Korea in online discourse?
    
    \item \textbf{RQ2 (Structural Reorganization)}: How do these diplomatic events restructure the organization of online discourse, as reflected in changes to discourse networks and narrative connectivity?
    
    \item \textbf{RQ3 (Methodological Validity)}: To what extent can LLM-based framing classification align with human expert judgments in geopolitical discourse analysis?
\end{itemize}

% === END: sections/introduction.tex ===
% === BEGIN: sections/related_work.tex ===
%==============================================================================
% RELATED WORK
%==============================================================================
\section{Related Work}

\subsection{Media Framing in International Discourse}

Framing theory examines how issues are selectively presented and organized to promote particular interpretations, evaluations, and responses \cite{entman1993}. Rather than merely conveying information, frames highlight certain aspects of reality while obscuring others, thereby shaping how audiences understand political events and actors. In the context of international affairs, framing is especially consequential, as foreign adversaries are often interpreted through simplified narratives emphasizing threat, cooperation, or moral evaluation.

A substantial body of communication research has identified recurring, domain-general frames in political news coverage. Semetko and Valkenburg \cite{semetko2000} propose five widely used generic news frames—conflict, economic consequences, human interest, attribution of responsibility, and morality—which have since served as a foundation for empirical framing studies across media systems and issue domains. Subsequent work has applied these frames to international relations contexts, demonstrating that security-related conflict, economic sanctions, and humanitarian concerns constitute dominant interpretive lenses in foreign policy reporting.

Within studies of international conflict and diplomacy, conflict-oriented frames emphasizing military threat, escalation, and security dilemmas are particularly prevalent, often shaping adversary images and public risk perceptions. At the same time, diplomatic engagement introduces alternative frames centered on negotiation, cooperation, and conflict resolution, which can substantially alter how adversarial states are discussed. Prior research suggests that these cooperative frames are not merely the absence of conflict framing, but constitute a distinct narrative logic emphasizing dialogue, reciprocity, and the possibility of peaceful change.

\subsection{Framing and Narrative Dynamics in International Politics}

Beyond identifying frame categories, framing research highlights the importance of narrative dynamics—how frames are linked, reinforced, and reorganized over time in response to political events \cite{entman1993}. In international politics, narratives connect events, actors, and causal interpretations into coherent storylines that shape collective understanding of foreign policy developments.

Prior framing studies have predominantly focused on traditional media outlets or small-scale manually coded datasets, limiting their ability to capture dynamic framing shifts in response to discrete diplomatic events. As a result, less is known about how framing evolves within large-scale, participatory online discussions, where narratives are co-produced by journalists, political elites, and the public. Understanding these dynamics is particularly important for diplomacy, where symbolic events such as summits may not only change evaluative tone but also reorganize how issues and actors are narratively connected.

Our work extends this literature by examining longitudinal changes in framing within online discourse and by analyzing how diplomatic engagement and failure reshape the narrative positioning of an adversary nation over time.

\subsection{Event-Driven Opinion Change in Foreign Policy}

A large body of research examines how major political and diplomatic events influence public opinion on foreign policy. Prior studies show that elite signaling, high-profile negotiations, and symbolic diplomatic actions can alter public attitudes by reshaping issue salience and interpretive contexts. These effects are most often studied through surveys or approval metrics, focusing on short-term affective responses to salient international events.

However, survey-based approaches primarily capture aggregate opinion shifts and provide limited insight into how foreign adversaries are discursively constructed in public communication. Moreover, they face challenges in capturing fine-grained temporal dynamics and attributing causal effects when multiple international developments unfold concurrently. As a result, existing approaches often miss how diplomatic events reconfigure the narrative dimensions through which adversaries are interpreted, beyond changes in approval or sentiment.

Our study builds on this literature by examining how discrete diplomatic summits causally reshape online discourse toward a foreign adversary, focusing on framing dynamics rather than approval or support.

\subsection{Online Discourse and Public Opinion on Social Media}

Social media platforms have become central venues for public deliberation on international politics. Research using platforms such as Twitter and Reddit has explored agenda-setting, polarization, and narrative diffusion in response to global events \cite{baumgartner2020}. Compared to Twitter, Reddit supports longer-form discussion and community-based topical organization, making it particularly well-suited for studying discursive framing rather than isolated reactions.

Nevertheless, much of the social media literature relies on descriptive or correlational analyses, limiting causal interpretation. Studies often document shifts in sentiment or topic prevalence without explicitly isolating the effects of discrete political interventions. Our study addresses this gap by applying a Difference-in-Differences design with multiple control countries, enabling causal inference about how summit diplomacy altered both sentiment and framing within online discourse.

\subsection{Large Language Models for Political Text Analysis}

Recent advances in large language models (LLMs) have enabled automated analysis of political text at unprecedented scale \cite{gilardi2023}. LLMs have been successfully applied to sentiment analysis, stance detection, and framing classification, reducing reliance on costly manual annotation and enabling longitudinal analysis across large corpora.

Despite these advances, concerns remain regarding construct validity and domain specificity, particularly for geopolitically sensitive content. Many studies deploy LLMs without systematic validation against expert human judgments, raising questions about reliability in specialized domains. Our work contributes to this emerging literature by constructing a gold-standard human annotation benchmark and explicitly validating LLM-based framing classification against expert consensus prior to using model outputs for causal analysis.

Together, these strands of research motivate a framing-centered, event-driven, and causally grounded analysis of online discourse surrounding diplomatic engagement.

% === END: sections/related_work.tex ===
% === BEGIN: sections/method.tex ===
%==============================================================================
% METHOD
%==============================================================================
\section{Method}

\subsection{Data Collection}

We collected Reddit posts from January 2017 to December 2019 using the Arctic Shift API, targeting major subreddits: r/worldnews, r/politics, r/news, r/geopolitics, and r/NeutralPolitics.

\subsubsection{Treatment and Control Groups}

\begin{table}[t]
\centering
\setlength{\tabcolsep}{3pt}
\caption{Dataset Overview}
\begin{tabular}{llrl}
\hline
\textbf{Group} & \textbf{Topic} & \textbf{N} & \textbf{Role} \\
\hline
Treatment & N. Korea & 10,659 & Primary \\
Control 1 & China & 8,024 & Trade confounder \\
Control 2 & Iran & 5,983 & Nuclear comparison \\
Control 3 & Russia & 10,261 & Investigation \\
\hline
\end{tabular}
\label{tab:dataset}
\end{table}

\subsubsection{Key Events and Analysis Periods}

To avoid anticipation effects, we define three analysis periods excluding transition months:
\begin{itemize}
    \item \textbf{P1} (2017.01--2018.02): Pre-Announcement
    \item \textbf{P2} (2018.06--2019.01): Singapore-Hanoi
    \item \textbf{P3} (2019.03--2019.12): Post-Hanoi
    \item \textit{Excluded}: 2018.03--05, 2019.02 (Transition periods)
\end{itemize}

Key diplomatic events include the Singapore Summit (2018-06-12), which marked peak diplomatic engagement, and the Hanoi Summit (2019-02-27), which ended without agreement.

%------------------------------------------------------------------------------
\subsection{Outcome Measurement}

We measure two complementary dimensions of discourse: \textit{framing} (how North Korea is narratively positioned) and \textit{sentiment} (emotional valence).

\subsubsection{Framing Classification}

We classify each Reddit post into one of five framing categories using GPT-4o-mini with zero-shot prompting:
\begin{itemize}
    \item \textbf{THREAT} (-2): Military threat, nuclear weapons, missiles, war risk
    \item \textbf{ECONOMIC} (-1): Economic sanctions, trade, and financial impacts
    \item \textbf{NEUTRAL} (0): Descriptive reporting without clear evaluative framing
    \item \textbf{HUMANITARIAN} (+1): Human rights, refugees, civilian welfare
    \item \textbf{DIPLOMACY} (+2): Negotiation, dialogue, summits, peace initiatives
\end{itemize}

The prompt provides category definitions and requires a single label output; the model also returns a confidence score.

\subsubsection{Sentiment Analysis}

We compute sentiment using a RoBERTa-based sentiment model\footnote{cardiffnlp/twitter-roberta-base-sentiment-latest}. Sentiment is mapped to a continuous score from -1 (negative) to +1 (positive). While framing captures \textit{how} North Korea is discussed, sentiment captures \textit{emotional valence}, enabling complementary measurement of content change.

\subsubsection{Human Annotation Benchmark}

To validate our LLM-based classification in a domain-sensitive setting, we constructed a gold-standard human annotation benchmark. Two military officers with expertise in North Korean affairs independently labeled 1,330 stratified samples (4 countries $\times$ 3 periods $\times$ 5 frames, minimum 10 posts per stratum).

We followed an iterative codebook refinement approach:
\begin{enumerate}
    \item \textbf{Pilot Round}: 100 posts labeled independently with reliability assessment
    \item \textbf{Main Annotation}: Remaining posts labeled in batches with periodic checks
    \item \textbf{Disagreement Resolution}: Structured discussion to produce consensus labels
\end{enumerate}

Inter-rater reliability (Cohen's $\kappa$) and LLM-human agreement metrics are reported in Section~5 (RQ3).

%------------------------------------------------------------------------------
\subsection{Causal Identification}

We estimate the causal impact of summit diplomacy using a Difference-in-Differences (DID) design with North Korea as the treated group and control countries (China, Iran, Russia) as comparisons.

\subsubsection{Difference-in-Differences Specification}

Our main specification uses two-way fixed effects:

\begin{equation}
Y_{g,t} = \alpha_g + \gamma_t + \beta \big(\text{Treat}_g \times \text{Post}_t\big) + \epsilon_{g,t},
\end{equation}

where $Y_{g,t}$ is the monthly average sentiment (or framing) for group $g$ in month $t$, 
$\alpha_g$ and $\gamma_t$ denote group and month fixed effects, and $\beta$ captures the DID estimate of the summit effect.
We report heteroskedasticity-robust standard errors clustered at the group level.

\subsubsection{Parallel Trends Validation}

We assess the parallel trends assumption by testing for differential pre-treatment trends between North Korea and each control group:

\begin{equation}
Y_{g,t} = \alpha + \delta_1 t + \delta_2 \text{Treat}_g + \delta_3 (t \times \text{Treat}_g) + \epsilon_{g,t},
\end{equation}

where $t$ is a linear month index in the pre-period. A statistically significant $\delta_3$ indicates a pre-trend violation. Results are reported in Section~5.

%------------------------------------------------------------------------------
\subsection{Additional Analyses: Network Structure}

Beyond content-level changes, we examine whether diplomatic events reorganize the \textit{structure} of discourse using GraphRAG~\cite{edge2024graphrag}. We construct knowledge graphs from Reddit discussions for each period, extracting entities (persons, countries, events, policies, weapons) and their relationships.

Network-level metrics include:
\begin{itemize}
    \item \textbf{Density}: Proportion of possible connections realized
    \item \textbf{Community structure}: Hierarchical clustering of narratives
    \item \textbf{Relationship framing}: Classification of edges as threat/peace/neutral
    \item \textbf{Keyword evolution}: Dominant themes in community summaries
\end{itemize}

This structural analysis addresses RQ2 by testing whether content-level framing shifts are accompanied by reorganization of discourse networks.

% === END: sections/method.tex ===
% === BEGIN: sections/results.tex ===
%==============================================================================
% RESULTS
%==============================================================================
\section{Results}

% Timeline figure at the beginning
\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1_timeline.png}
\caption{Research Timeline and Key Events. Shaded regions indicate analysis periods: P1 (gray), Transition (yellow), P2 (green), P3 (red).}
\label{fig:timeline}
\end{figure*}

\subsection{Content Changes in Online Discourse (RQ1)}

We first examine whether high-stakes diplomatic events causally reshape the content of online discourse toward North Korea. While sentiment captures short-term emotional responses, our primary focus is on framing, which reflects how North Korea is narratively positioned within geopolitical discourse. Together, these measures allow us to assess both affective and interpretive shifts following diplomatic events.

\subsubsection{Impact on Sentiment}

\begin{table}[t]
\centering
\caption{Parallel Trends Test Results (Sentiment)}
\begin{tabular}{llcc}
\hline
\textbf{Comparison} & \textbf{Control} & \textbf{P-value} & \textbf{OK} \\
\hline
P1$\rightarrow$P2 & China & 0.99 & \checkmark \\
P1$\rightarrow$P2 & Iran & 0.83 & \checkmark \\
P1$\rightarrow$P2 & Russia & [TBD] & [TBD] \\
P2$\rightarrow$P3 & China & 0.69 & \checkmark \\
P2$\rightarrow$P3 & Iran & 0.75 & \checkmark \\
P2$\rightarrow$P3 & Russia & [TBD] & [TBD] \\
\hline
\end{tabular}
\label{tab:pt_sentiment}
\end{table}

In the main specification, we use China and Iran as primary control groups because they satisfy parallel trends across both sentiment and framing. 
Russia is included as an additional robustness check due to partial pre-trend violations in the framing outcome.


The parallel trends tests indicate no significant pre-treatment differences between North Korea and the control countries, supporting the validity of the Difference-in-Differences design.

The Singapore Summit (P1$\rightarrow$P2) produced a statistically significant positive shift in sentiment toward North Korea across all control groups, with estimated effects ranging from +0.10 to +0.21 (p < 0.001). In contrast, the failure of the Hanoi Summit (P2$\rightarrow$P3) resulted in a significant negative shift in sentiment, ranging from -0.06 to -0.12 (p < 0.001).

\begin{figure}[t]
\centering
\includegraphics[width=0.95\columnwidth]{figures/fig6_sentiment_trends.png}
\caption{Monthly Sentiment Score Trends}
\label{fig:sentiment_trends}
\end{figure}

While these sentiment shifts are statistically significant, their magnitude remains modest relative to the scale of measurement, suggesting that diplomatic events influence affective tone without fundamentally transforming how North Korea is discussed.

\subsubsection{Impact on Framing}

We next examine changes in framing, where higher values indicate diplomacy-oriented narratives and lower values indicate threat-oriented narratives.

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig4_did_visualization.png}
\caption{Difference-in-Differences Visualization. (A) Singapore Summit Effect, (B) Hanoi Summit Effect.}
\label{fig:did}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig2_framing_trends.png}
\caption{Monthly Framing Score Trends: NK vs. Control Groups. Vertical lines mark key events.}
\label{fig:framing_trends}
\end{figure*}

\begin{table}[t]
\centering
\caption{Framing Difference-in-Differences Results}
\begin{tabular}{llcc}
\hline
\textbf{Event} & \textbf{Control} & \textbf{DID Est.} & \textbf{P-value} \\
\hline
Singapore & China & \textbf{+1.28} & $<$0.001 \\
(P1$\rightarrow$P2) & Iran & \textbf{+0.85} & $<$0.001 \\
\hline
Hanoi & China & \textbf{-0.88} & $<$0.001 \\
(P2$\rightarrow$P3) & Iran & \textbf{-0.30} & 0.003 \\
\hline
\end{tabular}
\label{tab:did_framing_summary}
\end{table}

The Singapore Summit led to a pronounced shift toward diplomacy-oriented framing, with DID estimates ranging from +0.85 to +1.28 across control groups. Following the collapse of the Hanoi Summit, framing shifted back toward threat-oriented narratives; however, this reversion was partial, with effect sizes (-0.30 to -0.88) substantially smaller than the preceding gains.

Notably, the magnitude of framing shifts substantially exceeds that of sentiment changes, indicating that diplomatic events more strongly reshape how North Korea is framed than how it is emotionally evaluated in online discourse.

Taken together, these findings demonstrate that high-stakes diplomatic summits significantly reshape the content of online discourse, particularly in terms of framing. We next examine whether these content-level shifts are accompanied by structural reorganization in how narratives are connected within discourse networks.

\subsection{Structural Reorganization of Discourse Networks (RQ2)}

To assess whether observed framing changes are reflected in the organization of discourse itself, we analyze discourse networks constructed from Reddit discussions across the three diplomatic phases. Using GraphRAG~\cite{edge2024graphrag}, we extract entities and relationships from 10,659 documents, constructing knowledge graphs that capture how actors, events, and concepts are interconnected in public discourse.

\subsubsection{Network Topology Changes}

Table~\ref{tab:network_topology} presents network-level metrics across the three periods. Despite a substantial reduction in the number of entities (nodes) and relationships (edges) from P1 to P3, network density---the proportion of possible connections that are realized---increased markedly (+146\% from P1 to P2, +16\% from P2 to P3). This densification indicates that discourse became more focused and interconnected around a smaller set of central actors and themes following the Singapore Summit.

The number of connected components decreased from 25 to 16, suggesting greater integration of previously fragmented discussion threads into a more unified discourse network. Clustering coefficients remained relatively stable, indicating that local community structure was preserved even as global connectivity increased.

% FILE NOT FOUND: tables/network_topology.tex

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_network_topology.png}
\caption{Network Topology Metrics Across Diplomatic Periods. (A) Network density increased despite fewer nodes, indicating discourse concentration. (B) Entity count declined as discussions focused on key actors. (C) Community count decreased, reflecting narrative consolidation.}
\label{fig:network_topology}
\end{figure*}

\subsubsection{Relationship Framing Shifts}

Beyond structural changes, we analyze the semantic content of relationships by classifying each edge based on keywords in its description. Table~\ref{tab:relationship_framing} and Figure~\ref{fig:framing_distribution} present the distribution of threat-oriented, peace-oriented, and neutral framings across periods.

% FILE NOT FOUND: tables/relationship_framing.tex

The results reveal a pronounced shift away from threat framing following the Singapore Summit: threat-oriented relationships decreased from 61.5\% in P1 to 42.4\% in P2 ($-19.1$ percentage points), while peace-oriented relationships more than tripled from 7.8\% to 24.7\% ($+16.9$ pp).

Critically, the Hanoi Summit failure produced only a partial reversion: threat framing declined marginally to 40.9\% ($-1.5$ pp), and peace framing decreased to 18.6\% ($-6.1$ pp). This asymmetric pattern---where diplomatic gains are largely preserved despite event failure---provides network-level evidence for the ``ratchet effect'' observed in content-level framing analysis (RQ1).

\begin{figure}[t]
\centering
\includegraphics[width=0.95\columnwidth]{figures/fig_framing_distribution.png}
\caption{Relationship Framing Distribution Across Periods. The Singapore Summit (P1$\rightarrow$P2) produced a 19pp decline in threat framing and 17pp increase in peace framing. The Hanoi failure (P2$\rightarrow$P3) caused only partial reversion.}
\label{fig:framing_distribution}
\end{figure}

\subsubsection{Community Theme Evolution}

Using hierarchical community detection, we identified 354, 153, and 107 communities in P1, P2, and P3 respectively. Table~\ref{tab:keyword_evolution} shows the evolution of dominant keywords in community descriptions across periods.

% FILE NOT FOUND: tables/keyword_evolution.tex

In P1, ``military'' was the most frequent keyword, reflecting the predominant threat-oriented discourse. By P2, ``nuclear'' and ``diplomatic'' rose in prominence, corresponding to summit-related discussions about denuclearization. Notably, new keywords emerged in P2 (``efforts,'' ``ongoing,'' ``united,'' ``states'') that were absent in P1, suggesting the introduction of cooperation-oriented vocabulary.

In P3, while some threat-related terms returned, diplomatic framing persisted: ``diplomatic'' remained among the top keywords, and new terms (``trump,'' ``political'') emerged, indicating continued focus on leadership-level negotiations rather than a return to purely military discourse.

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_keyword_evolution.png}
\caption{Top Keywords in Community Summaries by Period. (A) P1 dominated by ``military'' and ``security.'' (B) P2 shows rise of ``diplomatic'' and ``efforts.'' (C) P3 maintains diplomatic vocabulary while adding leadership-focused terms.}
\label{fig:keyword_evolution}
\end{figure*}

Taken together, these structural analyses demonstrate that the Singapore Summit not only shifted the content of discourse (RQ1) but also reorganized its underlying network structure, concentrating attention on diplomatic themes and actors. The persistence of these structural changes following the Hanoi failure reinforces the ``ratchet effect'' hypothesis: high-profile diplomatic engagement creates durable shifts in how public discourse is organized, even when negotiations fail.




\subsection{Validation of LLM-Based Framing (RQ3)}

To evaluate whether LLM-based framing classification can approximate expert human judgment in geopolitical discourse analysis, we constructed a gold-standard benchmark of 1,330 Reddit posts using stratified sampling across countries (North Korea, China, Iran, Russia), time periods (P1--P3), and frames (THREAT, ECONOMIC, NEUTRAL, HUMANITARIAN, DIPLOMACY). Two domain experts (military officers with expertise in North Korea and international security) independently annotated all samples following an iterative codebook refinement process.

\subsubsection{Inter-Rater Reliability}

We first assess annotation reliability on the independently produced labels prior to consensus. Overall agreement between annotators was [TBD]\%, with Cohen's $\kappa$ = [TBD], indicating [TBD: moderate/substantial/almost perfect] agreement under conventional interpretations (Landis \& Koch, 1977). Reliability was highest for [TBD: e.g., THREAT/DIPLOMACY] and comparatively lower for [TBD: e.g., NEUTRAL/ECONOMIC], consistent with the greater conceptual overlap among non-extreme frames.

\subsubsection{LLM--Human Agreement}

Using the final consensus labels as ground truth, we compare LLM predictions against the benchmark annotations. Overall accuracy was [TBD], with macro-F1 of [TBD]. Performance varied by frame category: the model achieved strong performance on salient frames (e.g., THREAT and DIPLOMACY) but showed more confusion among adjacent categories such as NEUTRAL vs.\ ECONOMIC and ECONOMIC vs.\ HUMANITARIAN. We report the full confusion matrix and per-class precision/recall/F1 in Table~\ref{tab:llm_human_metrics}.

\begin{table*}[t]
\centering
\caption{LLM vs.\ Human (Consensus) Validation Metrics}
\begin{tabular}{lcccc}
\hline
\textbf{Frame} & \textbf{Prec.} & \textbf{Rec.} & \textbf{F1} & \textbf{Support} \\
\hline
THREAT & [TBD] & [TBD] & [TBD] & [TBD] \\
ECONOMIC & [TBD] & [TBD] & [TBD] & [TBD] \\
NEUTRAL & [TBD] & [TBD] & [TBD] & [TBD] \\
HUMANITARIAN & [TBD] & [TBD] & [TBD] & [TBD] \\
DIPLOMACY & [TBD] & [TBD] & [TBD] & [TBD] \\
\hline
\textbf{Overall} &  &  & \textbf{Acc. [TBD]} &  \\
\textbf{Macro Avg.} & [TBD] & [TBD] & \textbf{[TBD]} &  \\
\hline
\end{tabular}
\label{tab:llm_human_metrics}
\end{table*}


\subsubsection{Error Analysis and Implications}

Qualitative inspection of disagreements suggests that most LLM errors arise in edge cases where multiple frames co-occur and the primary emphasis is ambiguous (e.g., sanction policy described alongside civilian harm, or diplomatic negotiations described in the context of military escalation). Importantly, these errors are unlikely to systematically favor one diplomatic phase over another because the benchmark was stratified across periods and countries. Taken together, these results support the validity of using LLM-based framing classification for large-scale causal analysis, while motivating targeted robustness checks (e.g., re-estimating DID effects on high-confidence predictions or excluding the most ambiguous categories).


\subsection{Robustness Checks}
\label{sec:robustness}

We conduct two robustness checks. 
First, we re-estimate the DID models using Russia as an additional control group; results remain directionally consistent, though effect sizes attenuate when pre-trend violations are present. 
Second, we repeat the framing DID analysis on a high-confidence subset of LLM predictions; estimated summit effects remain stable, suggesting that misclassification noise does not drive the main findings.

% === END: sections/results.tex ===
% === BEGIN: sections/discussion.tex ===
%==============================================================================
% DISCUSSION
%==============================================================================
\section{Discussion}

\subsection{Asymmetric Persistence of Diplomatic Effects}

Our findings reveal an asymmetric pattern in how diplomatic events shape online discourse toward North Korea. While the Singapore Summit produced substantial positive shifts in both sentiment (+0.10 to +0.21) and framing (+0.85 to +1.28), the subsequent failure of the Hanoi Summit resulted in comparatively smaller negative reversals (-0.06 to -0.12 in sentiment; -0.30 to -0.88 in framing).

Importantly, the negative effects of diplomatic failure did not fully offset the earlier gains from successful engagement. This pattern suggests an \emph{incomplete reversal} in public discourse, whereby positive reframing generated by diplomatic success exhibits persistence even after subsequent setbacks. Rather than returning to pre-summit baselines, discourse appears to stabilize at an intermediate state, indicating that framing shifts may be more durable than short-term sentiment reactions.

\subsection{Framing as a More Responsive Dimension than Sentiment}

A central contribution of this study lies in distinguishing between sentiment and framing as distinct dimensions of public discourse. Across all specifications, framing exhibited substantially larger effect sizes than sentiment, capturing approximately 25--32\% of its scale range compared to 5--10\% for sentiment.

This divergence suggests that diplomatic events primarily reshape \emph{how} foreign adversaries are interpreted and discussed, rather than merely influencing emotional valence. Framing reflects higher-level interpretive schemas that organize discourse, which may adjust rapidly in response to elite diplomatic signaling even when affective attitudes change more gradually. These findings highlight the importance of moving beyond sentiment-only analyses when studying public reactions to foreign policy events.

\subsection{Robustness Across Control Groups}

Our multi-control Difference-in-Differences design underscores the importance of careful control group selection in causal discourse analysis. Iran and China satisfy the parallel trends assumption across both sentiment and framing, while Russia exhibits partial violations, particularly for framing in the P1$\rightarrow$P2 comparison.

The consistency of estimated effects across control groups that meet parallel trends strengthens confidence in the causal interpretation of our results. At the same time, observed deviations for Russia illustrate how concurrent geopolitical developments can complicate inference, reinforcing the value of multiple comparison groups.

\subsection{From Content Shifts to Discourse Structure}

Beyond aggregate content changes, our findings motivate a structural interpretation of discourse dynamics. Changes in framing imply not only shifts in category prevalence but also potential reorganization of how narratives, actors, and themes are interconnected within discourse networks. This perspective motivates our GraphRAG analysis, which examines whether diplomatic events are associated with structural reconfiguration of discourse beyond surface-level content changes.

By linking framing shifts to changes in discourse structure, our approach moves toward a more holistic understanding of how diplomatic engagement reshapes public narratives in online spaces.

\subsection{Implications for Policy Communication}

These findings carry implications for diplomatic communication and public engagement strategies. First, high-profile diplomatic initiatives can rapidly alter interpretive frames within public discourse, even in adversarial contexts. Second, the persistence of positive framing following successful engagement suggests that diplomatic signaling may yield longer-lasting narrative effects than immediate sentiment responses. Finally, the divergence between framing and sentiment underscores the need for policymakers to consider narrative positioning alongside affective reactions when evaluating public responses to diplomacy.

\subsection{Limitations and Future Work}

Several limitations warrant consideration. First, Reddit users are not representative of the broader public, limiting external validity. Second, although our LLM-based framing classification is validated against expert annotations, systematic model biases may remain. Third, unobserved concurrent events may partially confound estimated effects despite our multi-control design. Future work could extend this approach to additional platforms, incorporate survey-based validation, and further explore structural discourse dynamics using network-based methods.

% === END: sections/discussion.tex ===
% === BEGIN: sections/conclusion.tex ===
% Conclusion
\section{Conclusion}

This study provides causal evidence of how high-stakes diplomatic summits affect public opinion framing on social media. Using a Difference-in-Differences design with validated LLM-based classification, we find that:

\begin{enumerate}
    \item The 2018 Singapore Summit produced significant positive shifts in both sentiment and framing toward North Korea
    \item The 2019 Hanoi Summit failure triggered partial reversals, but did not fully undo the positive gains
    \item This ``ratchet effect'' suggests that successful diplomacy can create durable changes in public discourse
\end{enumerate}

Our methodology---combining LLM classification with expert validation and rigorous causal inference---provides a template for studying public opinion dynamics around international events. Future work should extend this analysis to other diplomatic contexts and examine the mechanisms underlying opinion persistence.

% === END: sections/conclusion.tex ===

% Acknowledgments (uncomment for camera-ready)
% \section*{Acknowledgments}
% We thank...

% References
\bibliography{references}

% Paper Checklist (Required for ICWSM submission)
\newpage
\section*{Paper Checklist}

\begin{enumerate}

\item For most authors...
\begin{enumerate}
    \item Would answering this research question advance science without violating social contracts?
    \answerYes{Yes, this study examines public discourse and does not involve private data.}
    
    \item Do your main claims accurately reflect the paper's contributions?
    \answerYes{Yes, see Abstract and Section 1.}
    
    \item Do you clarify how the proposed methodological approach is appropriate?
    \answerYes{Yes, see Section 4 (Method) for DID justification.}
    
    \item Do you clarify what are possible artifacts in the data?
    \answerYes{Yes, we discuss platform-specific limitations in Section 6.}
    
    \item Did you describe the limitations of your work?
    \answerYes{Yes, see Section 6 (Discussion - Limitations).}
    
    \item Did you discuss potential negative societal impacts?
    \answerNA{NA, this is observational research on public discourse.}
    
    \item Did you discuss potential misuse of your work?
    \answerNA{NA, findings describe public opinion patterns.}
    
    \item Did you describe steps to prevent negative outcomes?
    \answerYes{Yes, we use aggregated data and do not identify individuals.}
    
    \item Have you ensured your paper conforms to ethics guidelines?
    \answerYes{Yes.}
\end{enumerate}

\item Additionally, if your study involves hypothesis testing...
\begin{enumerate}
    \item Did you clearly state assumptions?
    \answerYes{Yes, parallel trends assumption in Section 4 and 5.}
    
    \item Have you provided justifications for theoretical results?
    \answerYes{Yes, we validate assumptions empirically.}
    
    \item Did you discuss competing hypotheses?
    \answerYes{Yes, we use multiple control groups for robustness.}
    
    \item Have you considered alternative explanations?
    \answerYes{Yes, discussed in Section 6.}
    
    \item Did you address potential biases?
    \answerYes{Yes, see Limitations in Section 6.}
    
    \item Have you related results to existing literature?
    \answerYes{Yes, see Section 2 (Related Work).}
    
    \item Did you discuss implications?
    \answerYes{Yes, see Section 6 (Discussion).}
\end{enumerate}

\item Additionally, if you ran machine learning experiments...
\begin{enumerate}
    \item Did you include code and data?
    \answerTODO{Will be provided upon acceptance.}
    
    \item Did you specify training details?
    \answerYes{Yes, we specify LLM model and prompts in Section 4.}
    
    \item Did you report error bars?
    \answerYes{Yes, standard errors provided in DID tables.}
    
    \item Did you include compute resources?
    \answerYes{GPT-4o-mini API, RoBERTa on local GPU.}
    
    \item Do you justify evaluation appropriateness?
    \answerYes{Yes, we validate LLM against human experts.}
    
    \item Did you discuss misclassification costs?
    \answerYes{Yes, see validation agreement metrics.}
\end{enumerate}

\item Additionally, if using existing assets...
\begin{enumerate}
    \item Did you cite the creators?
    \answerYes{Yes, Arctic Shift API and model citations included.}
    
    \item Did you mention licenses?
    \answerYes{Reddit data via public API; models via standard licenses.}
    
    \item Did you include new assets?
    \answerTODO{Will provide framing-annotated dataset.}
    
    \item Did you discuss consent?
    \answerYes{Reddit posts are public; no identifiable information used.}
    
    \item Does data contain PII?
    \answerNo{No, we use only public posts with anonymized usernames.}
\end{enumerate}

\item Additionally, if you used crowdsourcing or human subjects...
\begin{enumerate}
    \item Did you include instructions?
    \answerYes{Yes, annotation guidelines described in Section 4.}
    
    \item Did you describe participant risks?
    \answerNA{NA, annotators are expert collaborators, not research subjects.}
    
    \item Did you include hourly wage?
    \answerNA{NA, annotators are collaborating researchers.}
    
    \item Did you discuss data storage?
    \answerYes{Annotations stored locally.}
\end{enumerate}

\end{enumerate}

\end{document}
